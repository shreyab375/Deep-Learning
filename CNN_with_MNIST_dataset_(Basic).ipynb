{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NDYSvdaNGfSr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset into train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7TDGcENGsJz",
        "outputId": "89458b1b-2f0f-4b13-8b90-1d43b8700c24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train data\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(\"\\n test data\")\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_ZpfhW9HCEF",
        "outputId": "a5cd1288-59dc-4443-92d5-fef06970d33a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "\n",
            " test data\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample only 20k images for training\n",
        "idx = np.random.randint(x_train.shape[0], size=20000) # sample 20k indices from 0-60,000\n",
        "x_train = x_train[idx, :]\n",
        "y_train = y_train[idx]\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N1vOmvqHL0m",
        "outputId": "97f19601-cea7-45b1-8d6f-37d340d6684d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 28, 28)\n",
            "(20000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify input dimensions of each image\n",
        "img_rows, img_cols = 28, 28\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# batch size, number of classes, epochs\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12"
      ],
      "metadata": {
        "id": "iHDBHgiBHYUW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape x_train and x_test\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "# convert class labels (from digits) to one-hot encoded vectors\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPZGombjH6rO",
        "outputId": "1c621ca2-becc-4ad2-b8be-6bdc1fa98687"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "(20000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert int to float\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# normalise\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "metadata": {
        "id": "05LFSfnxILM6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will build a network with:**\n",
        "\n",
        "two convolutional layers having 32 and 64 filters respectively,\n",
        "followed by a max pooling layer,\n",
        "and then Flatten the output of the pooling layer to give us a long vector,\n",
        "then add a fully connected Dense layer with 128 neurons, and finally\n",
        "add a softmax layer with 10 neurons"
      ],
      "metadata": {
        "id": "Uwrr6T2yIV2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = Sequential()\n",
        "\n",
        "# a keras convolutional layer is called Conv2D\n",
        "# help(Conv2D)\n",
        "# note that the first layer needs to be told the input shape explicitly\n",
        "\n",
        "# first conv layer\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape)) # input shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# second conv layer\n",
        "model.add(Conv2D(64, kernel_size=(3, 3),\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "#Flatten and put a fully connected network\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation ='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# softmax layer\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "# model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvPQF7qWIQs4",
        "outputId": "84ca78d8-e278-4a03-b073-9fbd3cd7c405"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 12, 12, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1179776   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1199882 (4.58 MB)\n",
            "Trainable params: 1199882 (4.58 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ddgAV0kDNt71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layer-1 (Conv2D): We have used 32 kernels of size (3, 3), and each kernel has a single bias, so we have 32 x 3 x 3 (weights) + 32 (biases) = 320 parameters (all trainable). Note that the kernels have only one channel since the input images are 2D (grayscale). By default, a convolutional layer uses stride of 1 and no padding, so the output from this layer is of shape 26 x 26 x 32, as shown in the summary above (the first element None is for the batch size).\n",
        "\n",
        "Layer-2 (Conv2D): We have used 64 kernels of size (3, 3), but this time, each kernel has to convolve a tensor of size (26, 26, 32) from the previous layer. Thus, the kernels will also have 32 channels, and so the shape of each kernel is (3, 3, 32) (and we have 64 of them). So we have 64 x 3 x 3 x 32 (weights) + 64 (biases) = 18496 parameters (all trainable). The output shape is (24, 24, 64) since each kernel produces a (24, 24) feature map.\n",
        "\n",
        "Max pooling: The pooling layer gets the (24, 24, 64) input from the previous conv layer and produces a (12, 12, 64) output (the default pooling uses stride of 2). There are no trainable parameters in the pooling layer.\n",
        "\n",
        "The Dropout layer does not alter the output shape and has no trainable parameters.\n",
        "\n",
        "The Flatten layer simply takes in the (12, 12, 64) output from the previous layer and 'flattens' it into a vector of length 12 x 12 x 64 = 9216.\n",
        "\n",
        "The Dense layer is a plain fully connected layer with 128 neurons. It takes the 9216-dimensional output vector from the previous layer (layer l-1) as the input and has 128 x 9216 (weights) + 128 (biases) = 1179776 trainable parameters. The output of this layer is a 128-dimensional vector.\n",
        "\n",
        "The Dropout layer simply drops a few neurons.\n",
        "\n",
        "Finally, we have a Dense softmax layer with 10 neurons which takes the 128-dimensional vector from the previous layer as input. It has 128 x 10 (weights) + 10 (biases) = 1290 trainable parameters.\n",
        "\n",
        "Thus, the total number of parameters are 1,199,882 all of which are trainable."
      ],
      "metadata": {
        "id": "Lezz_o7HNuTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "O_bEbGgAJahO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8T814a5Krvy",
        "outputId": "aff19ea0-4ba1-4845-e040-cd047979d492"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "157/157 [==============================] - 62s 390ms/step - loss: 2.3030 - accuracy: 0.1135 - val_loss: 2.2941 - val_accuracy: 0.1520\n",
            "Epoch 2/12\n",
            "157/157 [==============================] - 56s 358ms/step - loss: 2.2894 - accuracy: 0.1309 - val_loss: 2.2794 - val_accuracy: 0.1781\n",
            "Epoch 3/12\n",
            "157/157 [==============================] - 56s 356ms/step - loss: 2.2761 - accuracy: 0.1580 - val_loss: 2.2639 - val_accuracy: 0.2066\n",
            "Epoch 4/12\n",
            "157/157 [==============================] - 58s 368ms/step - loss: 2.2608 - accuracy: 0.1874 - val_loss: 2.2474 - val_accuracy: 0.2472\n",
            "Epoch 5/12\n",
            "157/157 [==============================] - 56s 357ms/step - loss: 2.2463 - accuracy: 0.2086 - val_loss: 2.2296 - val_accuracy: 0.3038\n",
            "Epoch 6/12\n",
            "157/157 [==============================] - 56s 355ms/step - loss: 2.2295 - accuracy: 0.2397 - val_loss: 2.2103 - val_accuracy: 0.3517\n",
            "Epoch 7/12\n",
            "157/157 [==============================] - 60s 384ms/step - loss: 2.2096 - accuracy: 0.2669 - val_loss: 2.1890 - val_accuracy: 0.3980\n",
            "Epoch 8/12\n",
            "157/157 [==============================] - 60s 382ms/step - loss: 2.1898 - accuracy: 0.3009 - val_loss: 2.1655 - val_accuracy: 0.4468\n",
            "Epoch 9/12\n",
            "157/157 [==============================] - 59s 376ms/step - loss: 2.1670 - accuracy: 0.3336 - val_loss: 2.1392 - val_accuracy: 0.4934\n",
            "Epoch 10/12\n",
            "157/157 [==============================] - 61s 386ms/step - loss: 2.1414 - accuracy: 0.3614 - val_loss: 2.1098 - val_accuracy: 0.5328\n",
            "Epoch 11/12\n",
            "157/157 [==============================] - 55s 352ms/step - loss: 2.1136 - accuracy: 0.3844 - val_loss: 2.0771 - val_accuracy: 0.5632\n",
            "Epoch 12/12\n",
            "157/157 [==============================] - 55s 349ms/step - loss: 2.0830 - accuracy: 0.4137 - val_loss: 2.0410 - val_accuracy: 0.5875\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x797746bf6830>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model on test data\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXPhgxscNcdP",
        "outputId": "52ef5232-586d-414c-ee09-0f1d4417594c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 8s 24ms/step - loss: 2.0410 - accuracy: 0.5875\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.041016101837158, 0.5874999761581421]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.metrics_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIVjLDvMNhBp",
        "outputId": "3c4b4b36-fcfe-4dc9-a22f-7a6e2aff4e74"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss', 'accuracy']\n"
          ]
        }
      ]
    }
  ]
}